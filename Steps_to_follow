*) Client script creation (spell check, preprocess) 
*) encode without tf.py_function https://colab.research.google.com/drive/1IAIeaTdl4bJlWxDJS6AXFnBCg1B92E5Z#scrollTo=NsaUPscGZ-Mq
###################################################### 
Base paper:-  http://www.iitp.ac.in/~sukanta.pcs15/pubs/WAT_2018_paper_12.pdf 
###########3333
Testing Rules

Flow test

for single_batch_size:
	model_capacity check
	input independent baseline
	randomness check
	initial loss check

for batch_size in [single, multiple]:
	run train pipeline
	run eval pipeline

Post-training improvements:-
    #) Hyper parameter tuning on beam size, length penalty, dropout, label smoothing
	#) Multiple occurences of stop values in beam search and stop repeated occurences of words
	#) Add (follow the same preprocessing in the tfds pipeline) in the client script and also remove vulgar words, add spell correction, lower casing 

Work on:-

	#) Client script
	#) embedding projector in tensorboard :- https://www.tensorflow.org/tensorboard/tensorboard_projector_plugin
	#) seperate out translation and summarize 
		#) metrics
		#) preprocess 
		#) start and end IDS
	#) run unit test for the last architecture


Things to watchout for when coding
########################################################
#) meaning full names
#) separate script for specific functions
#) functions should be small
#) one method that clearly say what it does
#) remove composite switch statements
#) identify memory leakage
#  one line space after function name and before return
#) check duplicate code
#) separate script for python ops
#) test cases on inference decoders
#################################
Expected improvements:-
	*) GPU profiler
	*) Make the model predict the output_seq_len
	*) Data augumentation https://colab.research.google.com/drive/1RGWrQv3e0CRDPDROQ3ZmUWTmlRljasGi?authuser=0#scrollTo=E9RYnn9VDE4N
	*) Tensorflow graph optimizations
    *) Tensorflow implementation of BERT score
##################
Additional enhancements
	a) Scheduled sampling :- perform teacher forcing or autoregressive training for a coin toss

