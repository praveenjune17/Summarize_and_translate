*) Client script creation (spell check, preprocess) 
*) encode without tf.py_function https://colab.research.google.com/drive/1IAIeaTdl4bJlWxDJS6AXFnBCg1B92E5Z#scrollTo=NsaUPscGZ-Mq

###################################################### 
Base paper http://www.iitp.ac.in/~sukanta.pcs15/pubs/WAT_2018_paper_12.pdf 
###########3333
Testing Rules

Flow test

for single_batch_size:
	model_capacity check
	input independent baseline
	randomness check
	initial loss check

for batch_size in [single, multiple]:
	run train pipeline
	run eval pipeline

# one line space after function name and before return
#) check duplicates
#) separate script for python ops

#) check the output of mask and loss
#) tokens per batch and find out at what number of tokens per batch does GPU runs out of memory
#) add early monitor check to unit test
#) gradient accumulation test

#) BLEU score scareBLEU or from official.transformer import compute_bleu
#) seperate out translation and summarize 
	#) metrics
	#) preprocess 
	#) start and end IDS
#####################################################

#) embedding projector in tensorboard
#) time taken for evaluation pipeline.
#) run evaluation pipeline for more batches

##########################################################
#) GPU profiler
#) Tensorflow graph optimizations


=======
a)  create a single project
Testing Rules
*) estimated memory calculation
*) seq length test
#####################################################
#) checkpoint test. run a model store its checkpoint and restart it
#) gradient accumulation check
#) remove eval_after bug
#) tokens per batch
#) filter function in preprocess
#) two architecutre:- vanilla transformer, BERT_based_NLG, change the configs accordingly
#) add decoding hyper parameters to config
#) hyper parameter tuning
#) BLEU score scareBLEU
########################################################
#) meaning full names
#) if same code is repeated then use a function
#) separate script for specific functions
#) functions should be small
#) one method that clearly say what it does
#) remove composite switch statements
#) identify memory leakage
####################################################
#) embedding projector in tensorboard
#) time taken for evaluation pipeline.
#) GPU profiler
#) Tensorflow graph optimizations
#) Tensorflow implementation of BERT score


